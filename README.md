# Reconocimiento de objetos en videovigilancia y almacenamiento en sistema distribuido

Este proyecto integra inteligencia artificial con almacenamiento distribuido para videovigilancia. Utiliza YOLO para detecci칩n de objetos y algoritmos para extraer caracter칤sticas. Los datos se gestionan en un cl칰ster con Hive sobre HDFS, permitiendo b칰squedas eficientes de objetos similares. Incluye una plataforma web y una API REST para an치lisis y visualizaci칩n.

## Tabla de Contenidos


1. [Caracter칤sticas Principales](#caracter칤sticas-principales)
2. [Requisitos Previos](#requisitos-previos)
3. [Estructura del Proyecto](#estructura-del-proyecto)
4. [Gu칤a de Instalaci칩n](#gu칤a-de-instalaci칩n)
5. [Configuraci칩n](#configuraci칩n)
6. [Uso](#uso)
7. [Arquitectura](#arquitectura)
8. [Contribuciones](#contribuciones)


## Caracter칤sticas Principales
- Detecci칩n precisa: Identificaci칩n de objetos y extracci칩n de caracter칤sticas clave en los videos mediante modelos de IA como YOLO.
- Almacenamiento escalable: Gesti칩n eficiente de grandes vol칰menes de datos estructurados utilizando Hive sobre HDFS en un cl칰ster distribuido.
- Plataforma web intuitiva: Interfaz para cargar videos, analizar objetos detectados y gestionar resultados de an치lisis.
- Integraci칩n API: Acceso program치tico para consultar y gestionar datos a trav칠s de una API RESTful en el cluster.

## Requisitos Previos

Antes de comenzar, aseg칰rate de tener instalados los siguientes componentes necesarios para cada parte del sistema:

### API (Python)
La API utiliza Python y requiere las siguientes bibliotecas y herramientas:  
- FastAPI  
- Uvicorn  
- Celery  
- Redis  
- PyHive  
- Thrift  
- Thrift-SASL  

### Inteligencia Artificial (Procesamiento de Videos)
El an치lisis y detecci칩n de objetos requiere las siguientes bibliotecas:  
- OpenAI (para tareas de procesamiento avanzado)  
- dotenv  
- OpenCV  
- NumPy  
- Ultralytics YOLO  

### Backend
El backend requiere:  
- Node.js  
- npm  

### Frontend
El frontend est치 desarrollado en React y requiere un entorno compatible con Node.js y npm.

### Infraestructura
El sistema se monta en un cl칰ster **Amazon EMR** para proporcionar escalabilidad y procesamiento distribuido. Aseg칰rate de configurar un cl칰ster adecuado con Hive y HDFS.  


## Estructura del Proyecto

El proyecto est치 organizado en varias carpetas principales que representan los diferentes componentes del sistema. A continuaci칩n, se proporciona una descripci칩n general de cada carpeta clave:

### 游늬 AI_cluster  
Contiene los scripts y herramientas relacionadas con el procesamiento y an치lisis de datos utilizando modelos de IA.  
- **Principales funciones:** generaci칩n de datos, detecci칩n de objetos con YOLO, detecci칩n de movimiento y procesamiento de videos.  
- **Archivos clave:**  
  - `main.py`: Punto de entrada para ejecutar el an치lisis principal.  
  - `src/`: Contiene m칩dulos como `gpt_detector.py` y `yolo_detection.py` para tareas espec칤ficas de IA.  

### 游늬 API_cluster  
Aloja la implementaci칩n de la API RESTful en Python.  
- **Principales funciones:** manejo de tareas en segundo plano (Celery), conexi칩n a Hive, y exposici칩n de datos procesados.  
- **Archivos clave:**  
  - `main.py`: Inicia la API con FastAPI.  
  - `tasks.py`: Gestiona tareas en segundo plano.  
  - `requirements.txt`: Lista de dependencias necesarias para el entorno.  
e
### 游늬 data_cluster  
Contiene los datos de entrada y scripts para cargar y gestionar tablas en Hive.  
- **Archivos clave:**  
  - `data_sd/`: Archivos CSV con datos de caracter칤sticas, objetos y escenarios.  
  - `deploy_hive.py`: Script para desplegar y configurar Hive.  
  - `querys.sql`: Consultas SQL predefinidas para el sistema.  

### 游늬 web_platform  
Contiene la implementaci칩n de la plataforma web.  
- **Backend:** Construido con Node.js, permite cargar videos y realizar an치lisis mediante la API.  
  - **Archivos clave:**  
    - `app.js`: Punto de entrada para el servidor backend.  
    - `controllers/`: L칩gica de control para procesar videos y gestionar resultados.  
  - **Carpetas adicionales:**  
    - `uploads/`: Almacena videos cargados por los usuarios.  
    - `detections/`: Resultados de an치lisis de videos, como im치genes y JSON.  
- **Frontend:** Construido con React, proporciona una interfaz para cargar videos, iniciar an치lisis y visualizar resultados.  
  - **Archivos clave:**  
    - `src/components/`: Componentes principales como botones, listas de videos y resultados.  
    - `App.js`: Entrada principal de la aplicaci칩n web.

    
## Gu칤a de Instalaci칩n

### 1. Clonar el repositorio

  ``` bash
    git clone https://github.com/angel452/Surveillance-IA-distributed.git
  ```

## 2. Crear el cl칰ster en AWS

Para comenzar, crea el cl칰ster de Amazon EMR. Aseg칰rate de que el cl칰ster est칠 configurado con Hive y HDFS para el almacenamiento distribuido.

### 3. Subir el c칩digo de la API y los datos al cl칰ster

Usa el siguiente comando scp para transferir las carpetas API_cluster y data_cluster al cl칰ster de EC2 en el nodo maestro:

  ``` bash
    scp -i "<ruta_a_tu_llave.pem>" -r API_cluster <usuario>@<direcci칩n_ec2>:/<ruta_destino>
    scp -i "<ruta_a_tu_llave.pem>" -r data_cluster <usuario>@<direcci칩n_ec2>:/<ruta_destino>
  ```

### 4. Configurar el entorno
Una vez que hayas subido los archivos, con칠ctate a tu instancia EC2 y aseg칰rate de que todas las dependencias necesarias est칠n instaladas:

- Para la API en Python, instala las dependencias utilizando pip:

    ``` bash
    pip install -r API_cluster/requirements.txt
    ```

### 5. Instanciar y crear las tablas en Hive

Para crear las tablas necesarias en Hive, entra como usuario root y ejecuta Hive desde la CLI:

1. Accede a la instancia EC2 como root:

    ``` bash
    sudo su 
    ```

2. Lanza la CLI de Hive:
    ``` bash
    hive
    ```
3. Dentro de la CLI de Hive, carga las consultas SQL para crear las tablas usando el archivo querys.sql ubicado en data_cluster o se puede colocar manualmente en el cli de hive todas las consultas:

    ``` bash
    source /home/ec2-user/data_cluster/querys.sql;
    ```

### 6. Iniciar el servidor de la API
Para iniciar el servidor de la API, usa el script `start.sh` dentro de la carpeta `API_cluster`. Si es necesario, puedes modificar el puerto en este archivo antes de ejecutarlo.

1. Navega a la carpeta `API_cluster`:
   ```bash
   cd API_cluster
   ```

2. Si necesitas cambiar el puerto en el que se ejecuta la API, edita el archivo start.sh y ajusta la configuraci칩n de puerto:

    ``` bash
    nano start.sh
    ``` 
3. Busca la l칤nea donde se define el puerto y modif칤calo seg칰n sea necesario.
    ``` bash
    ./start.sh
    ```
### 7. Levantar la Plataforma Web

1. Primero, instala las dependencias necesarias para Python, el backend y el frontend:

   - Navega a la carpeta `web_platform/backend/python` y ejecuta:
     ```bash
     cd web_platform/backend/python
     pip install -r requirements.txt
     ```

   - Luego, instala las dependencias de Node.js en el backend:
     ```bash
     cd ../
     npm install
     ```

   - Finalmente, instala las dependencias del frontend:
     ```bash
     cd ../../
     npm install
     ```

2. Para iniciar el servidor del backend, ejecuta:
   ```bash
   npm run server
   ```
3. Para iniciar el frontend, ejecuta:
   ```bash
    npm run start
   ```